{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90d31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the main tool. I have tried defining it into\n",
    "its own function, but loading model checkpoints does \n",
    "not seem to allow that. Nonetheless, it can be easily\n",
    "controlled from here\n",
    "\n",
    "This extracts the inner layers of a trained model, \n",
    "first by loading saved checkpoint of model\n",
    "then running a forward pass through the model\n",
    "\n",
    "As soon as this is placed inside a function,\n",
    "the ability to load the model is lost for some reason.\n",
    "\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import schnetpack as spk\n",
    "import math\n",
    "from schnetpack.datasets import QM9\n",
    "import os\n",
    "\n",
    "import numpy as np   \n",
    "from numpy import savetxt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "element = 'F'\n",
    "\n",
    "#inputs\n",
    "save_path = '../../data/schnet/%s/' %(element) \n",
    "main_name = 'rep'\n",
    "# convention dataset.energy.#training-#filters\n",
    "model_name = 'qm9energy10000-30'\n",
    "\n",
    "number_inputs=5000\n",
    "sub_name = ''\n",
    "qm9_file = '../../data/datasets/QM9/qm9.db'\n",
    "#label_file =  '../../data/labeldataset/%s/label%s%s.csv' %(element,element,number_inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6a7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9data = QM9(qm9_file, download=False, remove_uncharacterized=True)\n",
    "\n",
    "\n",
    "\n",
    "name_data = main_name + model_name + element + str(number_inputs) + sub_name\n",
    "\n",
    "#read in label file in order to output specific functional groups\n",
    "#label = pd.read_csv(label_file,delimiter=',')\n",
    "\n",
    "split_file='../../data/trainedmodels/%s/split.npz' %(model_name)\n",
    "checkpoint_path = '../../data/trainedmodels/%s/trained.pth' %(model_name)\n",
    "n_atom_basis=30\n",
    "n_filters=30\n",
    "n_gaussians=20\n",
    "n_interactions=3\n",
    "cutoff = 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c2cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global layer\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    layer=out_tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b56d6",
   "metadata": {},
   "source": [
    "# Full Representation X = X0 + V1 + V2 + V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f30ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aelsamma\\Anaconda3\\lib\\site-packages\\schnetpack\\data\\atoms.py:327: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  properties[pname] = torch.FloatTensor(prop)\n",
      "C:\\Users\\aelsamma\\Anaconda3\\lib\\site-packages\\ase\\atoms.py:967: VisibleDeprecationWarning: Use get_global_number_of_atoms() instead\n",
      "  warnings.warn('Use get_global_number_of_atoms() instead',\n"
     ]
    }
   ],
   "source": [
    "# Load split file \n",
    "train, val, test = spk.data.train_test_split(qm9data,split_file=split_file)\n",
    "\n",
    "# Load atom ref data \n",
    "atomrefs = qm9data.get_atomref(QM9.U0)\n",
    "\n",
    "# Define SchNet representation model\n",
    "\n",
    "schnet = spk.representation.SchNet(\n",
    "n_atom_basis=n_atom_basis, n_filters=n_filters, n_gaussians=n_gaussians, n_interactions=n_interactions,\n",
    "cutoff=cutoff , cutoff_network=spk.nn.cutoff.CosineCutoff\n",
    ")\n",
    "\n",
    "# Define SchNet output model and property to be predicted\n",
    "\n",
    "output_U0 = spk.atomistic.Atomwise(n_in=n_filters, atomref=atomrefs[QM9.U0])\n",
    "\n",
    "# Define atomistic model\n",
    "\n",
    "model = spk.AtomisticModel(representation=schnet,output_modules=output_U0)\n",
    "\n",
    "# Load saved checkpoint file\n",
    "load_checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "\n",
    "#qm9_i6_30f_20g-1000-500-4_300.pth\n",
    "# load model's state dictionary from saved checkpoint\n",
    "model.load_state_dict(load_checkpoint)\n",
    "\n",
    "\n",
    "#set up device for forward pass\n",
    "device='cpu'\n",
    "\n",
    "# load atoms converter \n",
    "converter = spk.data.AtomsConverter(device=device)\n",
    "\n",
    "data = np.zeros((1,31))\n",
    "dataae = np.zeros((1,1))\n",
    "countO = 0\n",
    "for idx in range(number_inputs):\n",
    "    at, props = qm9data.get_properties(idx)\n",
    "    inputs = converter(at)\n",
    "    \n",
    "    layer = None\n",
    "    \n",
    "    model.representation.embedding.register_forward_hook(hook)\n",
    "    model(inputs)\n",
    "    \n",
    "    emb = layer.clone()\n",
    "    emb = layer.detach().numpy()\n",
    "    \n",
    "    layer = None\n",
    "    \n",
    "    model.representation.interactions[0].register_forward_hook(hook)\n",
    "    \n",
    "    model(inputs)\n",
    "    int0 = layer.clone()\n",
    "    int0 = int0.detach().numpy()    \n",
    "\n",
    "    layer = None\n",
    "    \n",
    "    model.representation.interactions[1].register_forward_hook(hook)\n",
    "    \n",
    "    model(inputs)\n",
    "    int1 = layer.clone()\n",
    "    int1 = int1.detach().numpy()   \n",
    "    \n",
    "    layer = None \n",
    "    \n",
    "    model.representation.interactions[2].register_forward_hook(hook)\n",
    "    \n",
    "    model(inputs)   \n",
    "    \n",
    "    int2 = layer.clone()\n",
    "    int2 = int2.detach().numpy()   \n",
    "\n",
    "    rep = emb+int0+int1+int2\n",
    "    \n",
    "    number_atoms = len(props['_positions'])\n",
    "    \n",
    "\n",
    "    from schnetpack.atomistic.output_modules import yi\n",
    "    \n",
    "    rows = np.zeros((number_atoms,31))\n",
    "    for i in range(number_atoms):\n",
    "        for j in range(30):\n",
    "            rows[i][j] = rep[0][i][j]\n",
    "\n",
    "    \n",
    "    yi=yi.detach().numpy()\n",
    "    #save the vector of every oxygen atom encountered\n",
    "    \n",
    "    \n",
    "#    print(idx)\n",
    "    for i in range(number_atoms):\n",
    "#        if props['_atomic_numbers'][i] == 8:\n",
    "#            if label['Target'][countO] == 2:\n",
    "#                print(idx)\n",
    "#                datao = np.vstack((datao,rows[i]))\n",
    "#                dataoae = np.vstack((dataoae,yi[0][i])) \n",
    "#            countO = countO + 1\n",
    "\n",
    "        if element == 'H': \n",
    "            if props['_atomic_numbers'][i] == 1:\n",
    "                data = np.vstack((data,rows[i])) \n",
    "                dataae = np.vstack((dataae,yi[0][i]))\n",
    "        if element == 'O':\n",
    "            if props['_atomic_numbers'][i] == 8:\n",
    "                data = np.vstack((data,rows[i])) \n",
    "                dataae = np.vstack((dataae,yi[0][i]))\n",
    "        if element == 'N':\n",
    "            if props['_atomic_numbers'][i] == 7:\n",
    "                data = np.vstack((data,rows[i]))    \n",
    "                dataae = np.vstack((dataae,yi[0][i]))   \n",
    "        if element == 'C':\n",
    "            if props['_atomic_numbers'][i] == 6:\n",
    "                data = np.vstack((data,rows[i]))    \n",
    "                dataae = np.vstack((dataae,yi[0][i]))  \n",
    "        if element == 'F':\n",
    "            if props['_atomic_numbers'][i] == 9:\n",
    "                data = np.vstack((data,rows[i]))    \n",
    "                dataae = np.vstack((dataae,yi[0][i]))  \n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "data = np.delete(data, 0 ,axis=0)\n",
    "dataae = np.delete(dataae, 0 ,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f04a06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84a071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "savetxt(save_path+name_data+'.csv',data,delimiter=',')\n",
    "\n",
    "savetxt(save_path+name_data+'ae.csv',dataae,delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd710f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045a3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691edad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
