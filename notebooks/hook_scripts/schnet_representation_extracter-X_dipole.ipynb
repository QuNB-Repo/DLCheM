{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import schnetpack as spk\n",
    "import math\n",
    "from schnetpack.datasets import QM9\n",
    "\n",
    "import numpy as np\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_molecule(props):\n",
    "    \n",
    "    # load x,y,z coordinates tensors\n",
    "    x = props['_positions'][ :,0]\n",
    "    y = props['_positions'][ :,1]\n",
    "    z = props['_positions'][ :,2]\n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "    z = z.numpy()\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        if props['_atomic_numbers'][i] == 1:\n",
    "            print('H',x[i],y[i],z[i])\n",
    "        if props['_atomic_numbers'][i] == 6:\n",
    "            print('C',x[i],y[i],z[i])\n",
    "        if props['_atomic_numbers'][i] == 7:\n",
    "            print('N',x[i],y[i],z[i])     \n",
    "        if props['_atomic_numbers'][i] == 8:\n",
    "            print('O',x[i],y[i],z[i])\n",
    "        if props['_atomic_numbers'][i] == 9:\n",
    "            print('F',x[i],y[i],z[i]) \n",
    "    print('')  \n",
    "    return z\n",
    "\n",
    "def hook_v0(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global v0\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    v0=out_tensor \n",
    "\n",
    "def hook_v1(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global v1\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    v1=out_tensor \n",
    "\n",
    "def hook_v2(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global v2\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    v2=out_tensor  \n",
    "    \n",
    "def hook_emb(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global emb\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    emb=out_tensor \n",
    "#def convert_2D(number_of_atoms,rep):\n",
    "#    layer = np.zeros((number_of_atoms,30))\n",
    "#    for i in range(number_of_atoms):\n",
    "#        for j in range(30):\n",
    "#            layer[i][j] = rep[0][i][j]\n",
    "#    return layer\n",
    "def load_checkpoint(qm9data):\n",
    "    #Load split file \n",
    "    train, val, test = spk.data.train_test_split(qm9data,split_file=split_file)\n",
    "\n",
    "    # Load atom ref data \n",
    "    atomrefs = qm9data.get_atomref(QM9.mu)\n",
    "    # Define SchNet representation model\n",
    "\n",
    "    schnet = spk.representation.SchNet(\n",
    "        n_atom_basis=30, n_filters=30, n_gaussians=20, n_interactions=3,\n",
    "        cutoff=4. , cutoff_network=spk.nn.cutoff.CosineCutoff\n",
    "    )\n",
    "\n",
    "\n",
    "    train_loader = spk.AtomsLoader(train, batch_size=100, shuffle=True)\n",
    "    val_loader = spk.AtomsLoader(val, batch_size=100)\n",
    "    # Define SchNet output model and property to be predicted\n",
    "    means, stddevs = train_loader.get_statistics(QM9.mu, divide_by_atoms=True, single_atom_ref=atomrefs)\n",
    "\n",
    "    output_dip = spk.atomistic.DipoleMoment(n_in=30, property=QM9.mu,\n",
    "                                   mean=means[QM9.mu], contributions=None, stddev=stddevs[QM9.mu])\n",
    "    # Define atomistic model\n",
    "\n",
    "    model = spk.AtomisticModel(representation=schnet,output_modules=output_dip)\n",
    "\n",
    "    # Load saved checkpoint file\n",
    "    load_checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    #qm9_i6_30f_20g-1000-500-4_300.pth\n",
    "    # load model's state dictionary from saved checkpoint\n",
    "    model.load_state_dict(load_checkpoint)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "9\n",
      "C -0.017489549 1.2893138 0.0070837247\n",
      "C 0.0021349336 -0.16746153 -0.00095350837\n",
      "N 0.018049099 -1.3223433 -0.007233838\n",
      "H 1.0024261 1.6830851 -0.0005753772\n",
      "H -0.54359174 1.6669849 -0.873784\n",
      "H -0.5266811 1.6573676 0.9018339\n",
      "\n",
      "Prediction: 0.79049164\n",
      "Keys: ['_atomic_numbers', '_positions', '_cell', '_neighbors', '_cell_offset', '_atom_mask', '_neighbor_mask', 'representation']\n",
      "Truth: 0.79667646\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d59a7b071c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_atoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_atomic_numbers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mdatahae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatahae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_atoms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_atomic_numbers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# raise warning if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "checkpoint_path = '../../../../data/trained_models/qm9_dipole_trained_1000_500/trained.pth'\n",
    "split_file ='../../../../data/trained_models/qm9_dipole_trained_1000_500/split.npz'\n",
    "model_file = \"../../../../data/trained_models/qm9_dipole_trained_1000_500/best_model\"\n",
    "number_of_inputs = 5000\n",
    "\n",
    "# Load QM9 dataset\n",
    "qm9data = QM9('./qm9.db', download=True, remove_uncharacterized=True)\n",
    "\n",
    "model = load_checkpoint(qm9data)\n",
    "\n",
    "#set up device for forward pass\n",
    "device='cpu'\n",
    "\n",
    "# load atoms converter \n",
    "converter = spk.data.AtomsConverter(device=device)\n",
    "\n",
    "datao = np.zeros((1,30))\n",
    "datahae = np.zeros((1))\n",
    "dataoae = np.zeros((1))\n",
    "datah = np.zeros((1,30))\n",
    "for idx in range(9,10):\n",
    "        \n",
    "    # load data for molecule\n",
    "    at, props = qm9data.get_properties(idx)\n",
    "        \n",
    "    # print molecule for identification\n",
    "    print(idx)\n",
    "    z = print_molecule(props)\n",
    "    number_of_atoms=len(z)\n",
    "        \n",
    "    # convert qm9 data to machine-readable form\n",
    "    inputs = converter(at)\n",
    "        \n",
    "    #Instatiate layer output\n",
    "    v0=None\n",
    "    v1=None\n",
    "    v2=None\n",
    "    x=None       \n",
    "    \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.interactions[0].register_forward_hook(hook_v0)\n",
    "        \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.interactions[1].register_forward_hook(hook_v1)\n",
    "        \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.interactions[2].register_forward_hook(hook_v2)\n",
    "    \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.embedding.register_forward_hook(hook_emb)\n",
    " \n",
    "#    model = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    # Forward pass molecules through the model\n",
    "    pred = model(inputs)\n",
    "    \n",
    "    print('Prediction:', pred[QM9.mu].detach().cpu().numpy()[0,0])\n",
    "    print('Keys:', list(inputs.keys()))\n",
    "    print('Truth:', props[QM9.mu].cpu().numpy()[0])\n",
    "\n",
    "    rep = emb + v0 + v1 + v2\n",
    "    rows = np.zeros((number_of_atoms,30))\n",
    "    for i in range(number_of_atoms):\n",
    "        for j in range(30):\n",
    "            rows[i][j] = rep[0][i][j]\n",
    "            \n",
    "#    from schnetpack.atomistic.output_modules import y\n",
    "#    from schnetpack.atomistic.output_modules import yi\n",
    "#    from schnetpack.atomistic.output_modules import result\n",
    "#    from schnetpack.atomistic.output_modules import charges\n",
    "    \n",
    "#    y=y.detach().numpy()\n",
    "#    \n",
    "#    print(charges)\n",
    "#    print(yi)\n",
    "#    print(y)\n",
    "#    print(result)\n",
    "    \n",
    "    #save the vector of every oxygen atom encountered\n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 8:\n",
    "            datao = np.vstack((datao,rows[i]))\n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 1:\n",
    "            datah = np.vstack((datah,rows[i]))    \n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 1:\n",
    "            datahae = np.vstack((datahae,yi[0][i]))\n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 8:\n",
    "            dataoae = np.vstack((dataoae,yi[0][i]))            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')            \n",
    "savetxt('../../../data/dataO.csv',datao,delimiter=',')\n",
    "savetxt('../../../data/dataH.csv',datah,delimiter=',')\n",
    "savetxt('../../../data/hae.csv',datahae,delimiter=',')\n",
    "savetxt('../../../data/oae.csv',dataoae,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
