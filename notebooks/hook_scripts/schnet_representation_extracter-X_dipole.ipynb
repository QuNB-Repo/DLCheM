{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import schnetpack as spk\n",
    "import math\n",
    "from schnetpack.datasets import QM9\n",
    "\n",
    "import numpy as np\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_molecule(props):\n",
    "    \n",
    "    # load x,y,z coordinates tensors\n",
    "    x = props['_positions'][ :,0]\n",
    "    y = props['_positions'][ :,1]\n",
    "    z = props['_positions'][ :,2]\n",
    "    x = x.numpy()\n",
    "    y = y.numpy()\n",
    "    z = z.numpy()\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        if props['_atomic_numbers'][i] == 1:\n",
    "            print('H',x[i],y[i],z[i])\n",
    "        if props['_atomic_numbers'][i] == 6:\n",
    "            print('C',x[i],y[i],z[i])\n",
    "        if props['_atomic_numbers'][i] == 7:\n",
    "            print('N',x[i],y[i],z[i])     \n",
    "        if props['_atomic_numbers'][i] == 8:\n",
    "            print('O',x[i],y[i],z[i])\n",
    "        if props['_atomic_numbers'][i] == 9:\n",
    "            print('F',x[i],y[i],z[i]) \n",
    "    print('')  \n",
    "    return z\n",
    "\n",
    "def hook_v0(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global v0\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    v0=out_tensor \n",
    "\n",
    "def hook_v1(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global v1\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    v1=out_tensor \n",
    "\n",
    "def hook_v2(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global v2\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    v2=out_tensor  \n",
    "    \n",
    "def hook_emb(self, inp_tensor, out_tensor):\n",
    "    # Self is included and refers to the model class\n",
    "    # Global allows us to utilize embedding_output outside the current function scope\n",
    "    global emb\n",
    "    #Update the embedding_output variable to be equal to our output tensor\n",
    "    emb=out_tensor \n",
    "#def convert_2D(number_of_atoms,rep):\n",
    "#    layer = np.zeros((number_of_atoms,30))\n",
    "#    for i in range(number_of_atoms):\n",
    "#        for j in range(30):\n",
    "#            layer[i][j] = rep[0][i][j]\n",
    "#    return layer\n",
    "def load_checkpoint(qm9data):\n",
    "    #Load split file \n",
    "    train, val, test = spk.data.train_test_split(qm9data,split_file=split_file)\n",
    "\n",
    "    # Load atom ref data \n",
    "    atomrefs = qm9data.get_atomref(QM9.mu)\n",
    "    # Define SchNet representation model\n",
    "\n",
    "    schnet = spk.representation.SchNet(\n",
    "        n_atom_basis=30, n_filters=30, n_gaussians=20, n_interactions=3,\n",
    "        cutoff=4. , cutoff_network=spk.nn.cutoff.CosineCutoff\n",
    "    )\n",
    "\n",
    "\n",
    "    train_loader = spk.AtomsLoader(train, batch_size=100, shuffle=True)\n",
    "    val_loader = spk.AtomsLoader(val, batch_size=100)\n",
    "    # Define SchNet output model and property to be predicted\n",
    "    means, stddevs = train_loader.get_statistics(QM9.mu, divide_by_atoms=True, single_atom_ref=atomrefs)\n",
    "\n",
    "    output_dip = spk.atomistic.DipoleMoment(n_in=30, property=QM9.mu,\n",
    "                                   mean=means[QM9.mu], contributions=None, stddev=stddevs[QM9.mu])\n",
    "    # Define atomistic model\n",
    "\n",
    "    model = spk.AtomisticModel(representation=schnet,output_modules=output_dip)\n",
    "\n",
    "    # Load saved checkpoint file\n",
    "    load_checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    #qm9_i6_30f_20g-1000-500-4_300.pth\n",
    "    # load model's state dictionary from saved checkpoint\n",
    "    model.load_state_dict(load_checkpoint)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aelsamma\\Anaconda3\\lib\\site-packages\\schnetpack\\data\\atoms.py:327: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  properties[pname] = torch.FloatTensor(prop)\n",
      "C:\\Users\\aelsamma\\Anaconda3\\lib\\site-packages\\ase\\atoms.py:967: VisibleDeprecationWarning: Use get_global_number_of_atoms() instead\n",
      "  warnings.warn('Use get_global_number_of_atoms() instead',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "C -2.8340169e-06 2.3049886e-06 -1.4378233e-07\n",
      "H 0.014845718 -1.0918331 -0.0060250196\n",
      "H 1.0244261 0.3779494 -0.007724565\n",
      "H -0.52811974 0.36172476 -0.88464487\n",
      "H -0.5111183 0.3521308 0.89839613\n",
      "\n",
      "Prediction: -0.0033174977\n",
      "Keys: ['_atomic_numbers', '_positions', '_cell', '_neighbors', '_cell_offset', '_atom_mask', '_neighbor_mask', 'representation']\n",
      "Truth: 0.0\n",
      "[-0.12051509]\n",
      "[[[ 1.5303171e-03 -1.3085578e-01 -9.6424075e-04]\n",
      "  [ 2.0532962e-04 -5.7589239e-04  1.8868723e-04]\n",
      "  [ 9.6604437e-02  1.3976531e-01  2.6408561e-05]\n",
      "  [-5.1640589e-02  1.3821939e-01 -8.3707727e-02]\n",
      "  [-5.0016992e-02  1.3730277e-01  8.6548470e-02]]]\n",
      "tensor([[-0.0033,  0.2839,  0.0021]], grad_fn=<SumBackward1>)\n",
      "{'dipole_moment': tensor([[-0.0033,  0.2839,  0.0021]], grad_fn=<SumBackward1>)}\n",
      "[0.13086828 0.00063986 0.1699022  0.16964178 0.16983636]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '../../../../data/trained_models/qm9_dipole_trained/trained.pth'\n",
    "split_file ='../../../../data/trained_models/qm9_dipole_trained/split.npz'\n",
    "model_file = \"../../../../data/trained_models/qm9_dipole_trained/best_model\"\n",
    "number_of_inputs = 5000\n",
    "\n",
    "# Load QM9 dataset\n",
    "qm9data = QM9('./qm9.db', download=True, remove_uncharacterized=True)\n",
    "\n",
    "model = load_checkpoint(qm9data)\n",
    "\n",
    "#set up device for forward pass\n",
    "device='cpu'\n",
    "\n",
    "# load atoms converter \n",
    "converter = spk.data.AtomsConverter(device=device)\n",
    "\n",
    "datao = np.zeros((1,30))\n",
    "datahae = np.zeros((1))\n",
    "dataoae = np.zeros((1))\n",
    "datah = np.zeros((1,30))\n",
    "for idx in range(0,1):\n",
    "        \n",
    "    # load data for molecule\n",
    "    at, props = qm9data.get_properties(idx)\n",
    "        \n",
    "    # print molecule for identification\n",
    "    print(idx)\n",
    "    z = print_molecule(props)\n",
    "    number_of_atoms=len(z)\n",
    "        \n",
    "    # convert qm9 data to machine-readable form\n",
    "    inputs = converter(at)\n",
    "        \n",
    "    #Instatiate layer output\n",
    "    v0=None\n",
    "    v1=None\n",
    "    v2=None\n",
    "    x=None       \n",
    "    \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.interactions[0].register_forward_hook(hook_v0)\n",
    "        \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.interactions[1].register_forward_hook(hook_v1)\n",
    "        \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.interactions[2].register_forward_hook(hook_v2)\n",
    "    \n",
    "    # Forward hook the model's interaction layer \n",
    "    model.representation.embedding.register_forward_hook(hook_emb)\n",
    " \n",
    "#    model = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    # Forward pass molecules through the model\n",
    "    pred = model(inputs)\n",
    "    \n",
    "    print('Prediction:', pred[QM9.mu].detach().cpu().numpy()[0,0])\n",
    "    print('Keys:', list(inputs.keys()))\n",
    "    print('Truth:', props[QM9.mu].cpu().numpy()[0])\n",
    "\n",
    "    rep = emb + v0 + v1 + v2\n",
    "    rows = np.zeros((number_of_atoms,30))\n",
    "    for i in range(number_of_atoms):\n",
    "        for j in range(30):\n",
    "            rows[i][j] = rep[0][i][j]\n",
    "            \n",
    "    from schnetpack.atomistic.output_modules import y\n",
    "    from schnetpack.atomistic.output_modules import yi\n",
    "    from schnetpack.atomistic.output_modules import result\n",
    "    from schnetpack.atomistic.output_modules import charges\n",
    "    \n",
    "    charges = charges.detach().numpy()\n",
    "    yi=yi.detach().numpy()\n",
    "#    \n",
    "    print(charges[0][0])\n",
    "    print(yi)\n",
    "    print(y)\n",
    "    print(result)\n",
    "    \n",
    "    dip = np.zeros((number_of_atoms))\n",
    "    for i in range(number_of_atoms):\n",
    "        dip[i] = math.sqrt((yi[0][i][0])**2 + (yi[0][i][1])**2 + (yi[0][i][2])**2)\n",
    "    \n",
    "    print(dip)\n",
    "            \n",
    "        \n",
    "    #save the vector of every oxygen atom encountered\n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 8:\n",
    "            datao = np.vstack((datao,rows[i]))\n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 1:\n",
    "            datah = np.vstack((datah,rows[i]))    \n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 1:\n",
    "            datahae = np.vstack((datahae,dip[i]))\n",
    "    for i in range(number_of_atoms):\n",
    "        if props['_atomic_numbers'][i] == 8:\n",
    "            dataoae = np.vstack((dataoae,dip[i]))            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')            \n",
    "savetxt('../../../../data/dataO.csv',datao,delimiter=',')\n",
    "savetxt('../../../../data/dataH.csv',datah,delimiter=',')\n",
    "savetxt('../../../../data/hae.csv',datahae,delimiter=',')\n",
    "savetxt('../../../../data/oae.csv',dataoae,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
