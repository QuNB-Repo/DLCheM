{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U0 of hyrogen: -13.61 eV\n",
      "U0 of carbon: -1029.86 eV\n",
      "U0 of oxygen: -2042.61 eV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amerel/envs/dlchem/lib/python3.7/site-packages/schnetpack/data/atoms.py:327: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  properties[pname] = torch.FloatTensor(prop)\n",
      "/home/amerel/envs/dlchem/lib/python3.7/site-packages/ase/atoms.py:921: VisibleDeprecationWarning: Use get_global_number_of_atoms() instead\n",
      "  np.VisibleDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean atomization energy / atom: tensor([-4.2410])\n",
      "Std. dev. atomization energy / atom: tensor([0.1878])\n"
     ]
    }
   ],
   "source": [
    "# Train a SchNet model and store the outcome in ./trained_models/qm9_i6_30f_20g-1000-500-4/best_model\n",
    "\n",
    "import os\n",
    "import schnetpack as spk\n",
    "import torch\n",
    "import schnetpack.nn \n",
    "import schnetpack.data\n",
    "\n",
    "\n",
    "## Step 1 define the model\n",
    "\n",
    "#prepare directory for the output of the best model after training\n",
    "trained_model_path = '../../data/trained_models/qm9_gpu'\n",
    "if not os.path.exists('../../data/trained_models/qm9_gpu'):\n",
    "    os.makedirs(trained_model_path)\n",
    "\n",
    "# Download QM9 data set used for training and validation    \n",
    "\n",
    "from schnetpack.datasets import QM9\n",
    "\n",
    "\n",
    "qm9data = QM9('./qm9.db', download=True, remove_uncharacterized=True)\n",
    "\n",
    "# Define the number of training data and the number of validation data using split module\n",
    "\n",
    "train, val, test = spk.train_test_split(\n",
    "        data=qm9data,\n",
    "        num_train=10000,\n",
    "        num_val=5000,\n",
    "        split_file=os.path.join(trained_model_path, \"split.npz\"),\n",
    "    )\n",
    "\n",
    "# Define the loaders of training data and validation data and batch size\n",
    "\n",
    "train_loader = spk.AtomsLoader(train, batch_size=100, shuffle=True)\n",
    "val_loader = spk.AtomsLoader(val, batch_size=100)\n",
    "\n",
    "# Get reference atom data\n",
    "\n",
    "atomrefs = qm9data.get_atomref(QM9.U0)\n",
    "print('U0 of hyrogen:', '{:.2f}'.format(atomrefs[QM9.U0][1][0]), 'eV')\n",
    "print('U0 of carbon:', '{:.2f}'.format(atomrefs[QM9.U0][6][0]), 'eV')\n",
    "print('U0 of oxygen:', '{:.2f}'.format(atomrefs[QM9.U0][8][0]), 'eV')\n",
    "\n",
    "\n",
    "means, stddevs = train_loader.get_statistics(\n",
    "    QM9.U0, divide_by_atoms=True, single_atom_ref=atomrefs)\n",
    "\n",
    "\n",
    "print('Mean atomization energy / atom:', means[QM9.U0])\n",
    "print('Std. dev. atomization energy / atom:', stddevs[QM9.U0])\n",
    "\n",
    "# Define SchNet embedding representation model\n",
    "\n",
    "schnet = spk.representation.SchNet(\n",
    "    n_atom_basis=30, n_filters=30, n_gaussians=20, n_interactions=6,\n",
    "    cutoff=4., cutoff_network=spk.nn.cutoff.CosineCutoff\n",
    ")\n",
    "\n",
    "# Define output model and property to be predicted\n",
    "\n",
    "output_U0 = spk.atomistic.Atomwise(n_in=30, atomref=atomrefs[QM9.U0], property=QM9.U0,\n",
    "                                   mean=means[QM9.U0], contributions=True, stddev=stddevs[QM9.U0])\n",
    "model = spk.AtomisticModel(representation=schnet, output_modules=output_U0)\n",
    "\n",
    "## Training and Validation \n",
    "# NOTE You must delete previous best_model if you want to restart the training!\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "# loss function\n",
    "def mse_loss(batch, result):\n",
    "    diff = batch[QM9.U0]-result[QM9.U0]\n",
    "    err_sq = torch.mean(diff ** 2)\n",
    "    return err_sq\n",
    "\n",
    "# build optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "import schnetpack.train as trn\n",
    "\n",
    "loss = trn.build_mse_loss([QM9.U0])\n",
    "\n",
    "metrics = [spk.metrics.MeanAbsoluteError(QM9.U0)]\n",
    "hooks = [\n",
    "    trn.CSVHook(log_path=trained_model_path, metrics=metrics),\n",
    "    trn.ReduceLROnPlateauHook(\n",
    "        optimizer,\n",
    "        patience=5, factor=0.8, min_lr=1e-6,\n",
    "        stop_after_min=True\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = trn.Trainer(\n",
    "    model_path=trained_model_path,\n",
    "    model=model,\n",
    "    hooks=hooks,\n",
    "    loss_fn=loss,\n",
    "    optimizer=optimizer,\n",
    "    keep_n_checkpoints = 10,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    ")\n",
    "\n",
    "device = \"cuda\" # change to 'cpu' if gpu is not available\n",
    "n_epochs = 1000 # takes about 10 min on a notebook GPU. reduces for playing around\n",
    "trainer.train(device=device, n_epochs=n_epochs)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ase.units import kcal, mol\n",
    "\n",
    "results = np.loadtxt(os.path.join(trained_model_path, 'log.csv'), skiprows=1, delimiter=',')\n",
    "\n",
    "time = results[:,0]-results[0,0]\n",
    "learning_rate = results[:,1]\n",
    "train_loss = results[:,2]\n",
    "val_loss = results[:,3]\n",
    "val_mae = results[:,4]\n",
    "\n",
    "print('Final validation MAE:', np.round(val_mae[-1], 2), 'eV =',\n",
    "      np.round(val_mae[-1] / (kcal/mol), 2), 'kcal/mol')\n",
    "\n",
    "#plt.figure(figsize=(14,5))\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.plot(time, val_loss, label='Validation')\n",
    "#plt.plot(time, train_loss, label='Train')\n",
    "#plt.yscale('log')\n",
    "#plt.ylabel('Loss [eV]')\n",
    "#plt.xlabel('Time [s]')\n",
    "#plt.legend()\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.plot(time, val_mae)\n",
    "#plt.ylabel('mean abs. error [eV]')\n",
    "#plt.xlabel('Time [s]')\n",
    "#plt.show()\n",
    "\n",
    "torch.save(model.state_dict(), '../../../data/trained_models/qm9_gpu/qm9_benchmark.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training and Validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
