## Introduction
Modern material design and drug discovery would not have been possible if it were not for the pioneering efforts of computational chemists. They discovered that beneath the periodic and predictable behavior of chemistry is a mathematical framework that explains it all. However profound this discovery, it came with a pesky caveat: The solutions to the exact quantum equations is far too complex for relevant systems and they would have to be approximated. For decades chemists have worked developing such approximations with increasing complexity and basis set size. However, even with all this tremendous effort it is clear that we need much more powerful and faster tools to explore the immensity of the chemical space. This is where deep learning technology is hoping to make a great contribution. 

deep learning technology use what existing data we have (from the many approximations collected over decades) to predict properties about new (not originally inputted) molecular data.There is strong evidence that deep learning techniques have this capacity but how do they perform this task without directly solving the quantum equations? More importantly, can this tell us something about our theories and approximations?

The hypothesis is that a deep learning algorithm acts as a proxy to the human brain. That is, it is an artificial agent for chemical intelligence. Like chemists, these neural networks seemed to have learned something general about chemical systems. If this is true, then it must be possible to show how these algorithms are learning quantum chemical concepts be examining their internal neural network activity. This is called the interpretability of the neural network. This work is in motivation to understand how deep learning techniques learn (and thus improve them) and to understand the extense of knowledge we can extract from quantum chemical approximations.

## Methodology
To begin my investigation into the interpretability of deep learning models I will use statistical techniques such as 1) PCA, 2) TSNE, and 3) TCAV to find correlations between chemical concepts and the information passing through the popular SchNet deep learning algorithm. 1) Principal component analysis (PCA) is a technique used to reduce the high dimensionality of neural network information so that the data and its correlations can be easily visualized. This will help show if the neural network categorizes the data according to correct chemical intution. 2) t-stochastic neighborhood embedding (TSNE) is a similar technique to PCA but much more powerful for visualizing high-dimensional data. Lastly, 3) testing with concept activation vectors (TCAV) is a technique whereby a classifier is built around the neural activity of a chemical concept. This classifier will identify when a particular concept is being activated just by training with examples. 

## Results & Discussion
So far, I have extracted principal components (PCs) on many layers of the SchNet algorithm and there is evidence that SchNet is making chemically informed decisions. The graphs of 1-atom PCA appear to be clustering in different areas and this seems to be pointing to the fact that SchNet is learning functional group chemistry and how one atom can pertain to different categories depending on the functional group it is in.

## Conclusions
It is not yet time to make any solid conclusions but I expect to find correlations between neural network activity of SchNet and chemical concepts proving the efficacy of deep learning algorithms in exploring the chemical space and granting us deeper insights into their workings. 
