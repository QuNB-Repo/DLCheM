{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label functional groups of a molecular database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autolabeller, depending on how deep you want to look into F.G (n_perts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autolabel2\n",
    "\n",
    "'''\n",
    "Last Updated: 2024-02-24\n",
    "\n",
    "This code executes the autolabel code, a program that can label\n",
    "the atoms of any dataset according to their atomic environments\n",
    "AT ANY DEPTH SPECIFIED \n",
    "\n",
    "LABELING ATOMIC ENVIRONMENTS AUTOMATICALLY AT ANY DEPTH FROM AN ATOMIC CENTER\n",
    "\n",
    "(SOLVES A COMBINATORIAL PROBLEM IN REAL TIME!)\n",
    "\n",
    "        n_depth             - depth of the labelling of each atomic environment (1 = 1 bond away, 2 = 2 bonds away... etc)\n",
    "        elements            - elements found in the dataset to label, or elements to focus on\n",
    "        start               - start point of labelling the dataset\n",
    "        end                 - end point of labelling the dataset\n",
    "        qm9                 - boolean to confirm that the qm9 db dataset is being loaded \n",
    "                              as there is a faster way of loading that dataset using QM9 METHOD from SchNet.\n",
    "                              Other db datasets are loaded with AtomsData if this is set to False\n",
    "        dataset_filepath    - filepath location of the dataset to be labelled\n",
    "        scratch_direc       - directory which will hold scratch file, can be deleted, just a mol/xyz file that was used in the process of finding bonds\n",
    "        output_filepath     - output filepath where the label of the autlabel.label method will output\n",
    "       \n",
    "        autolabel.label     - the main method executed that autolabels the dataset\n",
    "                              the output is a file in label_direc that contains all the labels\n",
    "\n",
    "        unique_label_count  - the method returns how many TOTAL UNIQUE labels found at so and so depth\n",
    "'''\n",
    "\n",
    "for each_depth in range(5,6):\n",
    "        n_depth = each_depth\n",
    "        elements = ['H','C','N','O','F']\n",
    "\n",
    "        start = 9000\n",
    "        end = 10000\n",
    "\n",
    "        qm9 = True\n",
    "        #dataset_filepath = 'temp/pklabels/pK1Test.db' \n",
    "        dataset_filepath = '../../data/datasets/QM9/qm9.db'\n",
    "\n",
    "        output_filepath = '../../5full10000.csv' # %(each_depth)\n",
    "        scratch_direc = 'scratch/'\n",
    "\n",
    "        gather_pertemb_rep = True\n",
    "        embeddings_filepath = '../../data/embs/old/model1-10000/layer5/embslayer5pca10.csv'\n",
    "        prev_emb_filepath = '../../Y3pred.csv'\n",
    "        n_features = 10\n",
    "        n_pert = 1\n",
    "        X_savefilepath = '../../X1.csv'\n",
    "        Y_savefilepath = '../../Y1true.csv'\n",
    "\n",
    "        unique_label_count = autolabel2.label(output_filepath,start,end,qm9,dataset_filepath,n_depth,elements,gather_pertemb_rep,embeddings_filepath,n_features,n_pert,X_savefilepath,Y_savefilepath,prev_emb_filepath,scratch_direc)\n",
    "        print(each_depth, unique_label_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = np.genfromtxt('../../X1.csv',delimiter=',')\n",
    "Y = np.genfromtxt('../../Y1true.csv',delimiter=',')\n",
    "\n",
    "print(np.shape(X))\n",
    "\n",
    "X = X[:, ~(X == 0).all(axis=0)]\n",
    "print(np.shape(X))\n",
    "\n",
    "n_features = 10\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, Y[:,:n_features])\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr.predict(X)\n",
    "#    predictions = scaler_y.inverse_transform(predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y[:,:n_features], predictions)\n",
    "r2 = r2_score(Y[:,:n_features], predictions)\n",
    "\n",
    "new_rep = predictions\n",
    "\n",
    "\n",
    "print(mse)\n",
    "print(r2)\n",
    "\n",
    "predictions = np.hstack((predictions,Y[:,n_features:]))\n",
    "\n",
    "np.savetxt('../../Y1pred.csv',predictions,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autolabel2\n",
    "\n",
    "'''\n",
    "Last Updated: 2024-02-24\n",
    "\n",
    "This code executes the autolabel code, a program that can label\n",
    "the atoms of any dataset according to their atomic environments\n",
    "AT ANY DEPTH SPECIFIED \n",
    "\n",
    "LABELING ATOMIC ENVIRONMENTS AUTOMATICALLY AT ANY DEPTH FROM AN ATOMIC CENTER\n",
    "\n",
    "(SOLVES A COMBINATORIAL PROBLEM IN REAL TIME!)\n",
    "\n",
    "        n_depth             - depth of the labelling of each atomic environment (1 = 1 bond away, 2 = 2 bonds away... etc)\n",
    "        elements            - elements found in the dataset to label, or elements to focus on\n",
    "        start               - start point of labelling the dataset\n",
    "        end                 - end point of labelling the dataset\n",
    "        qm9                 - boolean to confirm that the qm9 db dataset is being loaded \n",
    "                              as there is a faster way of loading that dataset using QM9 METHOD from SchNet.\n",
    "                              Other db datasets are loaded with AtomsData if this is set to False\n",
    "        dataset_filepath    - filepath location of the dataset to be labelled\n",
    "        scratch_direc       - directory which will hold scratch file, can be deleted, just a mol/xyz file that was used in the process of finding bonds\n",
    "        output_filepath     - output filepath where the label of the autlabel.label method will output\n",
    "       \n",
    "        autolabel.label     - the main method executed that autolabels the dataset\n",
    "                              the output is a file in label_direc that contains all the labels\n",
    "\n",
    "        unique_label_count  - the method returns how many TOTAL UNIQUE labels found at so and so depth\n",
    "'''\n",
    "\n",
    "for each_depth in range(5,6):\n",
    "        n_depth = each_depth\n",
    "        elements = ['H','C','N','O','F']\n",
    "\n",
    "        start = 9000\n",
    "        end = 10000\n",
    "\n",
    "        qm9 = True\n",
    "        #dataset_filepath = 'temp/pklabels/pK1Test.db' \n",
    "        dataset_filepath = '../../data/datasets/QM9/qm9.db'\n",
    "\n",
    "        output_filepath = '../../5full10000.csv' # %(each_depth)\n",
    "        scratch_direc = 'scratch/'\n",
    "\n",
    "        gather_pertemb_rep = True\n",
    "        embeddings_filepath = '../../data/embs/old/model1-10000/layer5/embslayer5pca10.csv'\n",
    "        prev_emb_filepath = '../../Y1pred.csv'\n",
    "        n_features = 10\n",
    "        n_pert = 2\n",
    "        X_savefilepath = '../../X2.csv'\n",
    "        Y_savefilepath = '../../Y2true.csv'\n",
    "\n",
    "        unique_label_count = autolabel2.label(output_filepath,start,end,qm9,dataset_filepath,n_depth,elements,gather_pertemb_rep,embeddings_filepath,n_features,n_pert,X_savefilepath,Y_savefilepath,prev_emb_filepath,scratch_direc)\n",
    "        print(each_depth, unique_label_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = np.genfromtxt('../../X2.csv',delimiter=',')\n",
    "Y = np.genfromtxt('../../Y2true.csv',delimiter=',')\n",
    "\n",
    "n_features = 10\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, Y[:,:n_features])\n",
    "\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr.predict(X)\n",
    "#    predictions = scaler_y.inverse_transform(predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(Y[:,:n_features], predictions)\n",
    "r2 = r2_score(Y[:,:n_features], predictions)\n",
    "\n",
    "new_rep = predictions\n",
    "\n",
    "\n",
    "print(mse)\n",
    "print(r2)\n",
    "\n",
    "predictions = np.hstack((predictions,Y[:,n_features:]))\n",
    "\n",
    "np.savetxt('../../Y2pred.csv',predictions,delimiter=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('embs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e527e0fb9cd72c404b77fc0eaab204e19d8957c418c0845e3410ddf58030085"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
