{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick LR and MLP from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression - Set Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 136)\n",
      "[2.4  2.5  2.03 4.17 4.43 4.43 4.43 8.83 8.08 8.83 9.12 6.51 6.51 0.89\n",
      " 0.89 0.89 1.67 1.37 3.99 3.18 3.18 1.56 1.56 1.86 1.86 3.75 3.02 3.02\n",
      " 1.72 1.72 1.46 1.46 1.9  1.9  3.75 3.99 3.28 3.12 7.33 7.43 7.38 7.43\n",
      " 7.33 8.23 8.19 0.86 0.86 0.86 1.28 1.28 1.28 1.28 1.54 1.54 2.16 2.16\n",
      " 2.73 2.73 2.73 3.6  3.6  3.93 3.18 3.03 7.18 6.89 6.89 7.18 3.23 3.23\n",
      " 2.92 2.92 7.21 6.9  6.9  7.21 0.85 0.85 0.85 1.27 1.27 1.27 1.27 1.27\n",
      " 1.27 1.27 1.27 1.53 1.53 2.16 2.16 3.03 3.03 3.03 4.05 4.05 8.18 8.2\n",
      " 3.42 3.42 7.16 6.86 6.86 7.16 2.4  2.4  2.4  2.4  7.03 7.03 3.69 3.69\n",
      " 3.69 7.69 3.16 3.07 3.96 7.01 0.98 0.98 0.98 2.26 1.03 1.03 1.03 3.6\n",
      " 2.44 2.44 2.13 2.13 3.77 0.93 0.93 0.93 1.46 1.26 1.96 1.   1.   1.\n",
      " 3.66 3.53 3.53 7.37 7.3  7.3  7.3  7.37 7.67 4.64 4.64 7.44 7.42 7.38\n",
      " 7.42 7.44 4.12 2.34 2.06 2.   2.   3.41 3.33 8.24 8.34 6.06 4.29 3.91\n",
      " 3.83 4.43 4.81 3.75 3.75 3.75 8.16 7.17 3.24 3.31 3.96 3.93 3.78 3.7\n",
      " 4.58 3.49 3.64 3.85 7.59 8.7  8.24 8.92 1.24 1.24 1.24 4.13 4.13 2.07\n",
      " 2.07 2.07 2.36 2.36 2.36 3.54 3.54 3.17 3.17 2.55 2.55 3.   3.   1.89\n",
      " 1.89 2.29 2.29 1.15 1.15 1.15 2.54 1.15 1.15 1.15 6.43 4.39 3.7  3.98\n",
      " 2.75 2.18 4.08 3.81 3.71 3.75 2.04 2.12 2.35 2.35 3.03 3.03 3.03 3.92\n",
      " 3.92 7.8  6.91 6.91 7.8  3.98 3.24 3.15 7.09 7.88 0.86 0.86 0.86 1.28\n",
      " 1.28 1.28 1.28 1.6  1.6  2.36 2.36 4.15 4.15 1.24 1.24 1.24 4.05 3.47\n",
      " 3.29 7.31 7.53 7.19 7.27 7.72 1.32 1.32 1.32 4.24 3.58 1.27 1.27 1.27\n",
      " 4.22 4.22 4.39 1.4  1.4  1.4  6.05 7.83 5.9  4.12 3.92 3.81 4.2  4.3\n",
      " 0.93 0.93 0.93 2.09 0.93 0.93 0.93 2.6  2.6  7.95 6.27 2.75 2.48 4.6\n",
      " 4.1  3.79 3.73 2.71 2.71 2.71 2.71 2.71 2.71]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Load data into a Pandas DataFrame\n",
    "x_data = genfromtxt('../data/npmrd/embsnmr.csv',delimiter=',',encoding='utf-8-sig',skip_header=1)\n",
    "#x_data2 = genfromtxt('../data/embs/modelbreak/10-2-128-50-6-50/Oembslayer5-110000-120000-10dp.csv',delimiter=',',encoding='utf-8-sig',skip_header=1)\n",
    "\n",
    "print(x_data.shape)\n",
    "\n",
    "# Split data into X and y\n",
    "X = x_data[:,0:128]\n",
    "#128 --> pka & nmr\n",
    "#138 onwards --> electron density \n",
    "y = x_data[:,135]\n",
    "print(y)\n",
    "\n",
    "#label to split as well\n",
    "label = x_data[:,129:133]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test, label_train, label_test = train_test_split(X, y, label, test_size=0.2, random_state=50)\n",
    "\n",
    "use_train_for_test = True\n",
    "\n",
    "\n",
    "#save_pred_filepath = '../data/embs/embspKA-stef/lrtrainpredictions' #NO .csv!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the linear fitting, output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error: 0.2044289548237223\n",
      "R-squared: 0.9920165545067507\n"
     ]
    }
   ],
   "source": [
    "# Transform features to quadratic form\n",
    "#poly = PolynomialFeatures(degree=2)  # Use degree 2 for quadratic regression\n",
    "#X_train = poly.fit_transform(X_train)\n",
    "#X_test = poly.fit_transform(X_test)\n",
    "\n",
    "# Create a LinearRegression object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Standardize the data\n",
    "#scaler_X = StandardScaler()\n",
    "#scaler_y = StandardScaler()\n",
    "\n",
    "#X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "#X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "#y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n",
    "#y_test_scaled = scaler_y.transform(y_test.reshape(-1,1))\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "if use_train_for_test == True:\n",
    "    # Make predictions\n",
    "    predictions = lr.predict(X_train)\n",
    "#    predictions = scaler_y.inverse_transform(predictions)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    r2 = r2_score(y_train, predictions)\n",
    "else:\n",
    "    # Make predictions\n",
    "    predictions = lr.predict(X_test)\n",
    "#    predictions = scaler_y.inverse_transform(predictions_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print('Mean error:', math.sqrt(mse))\n",
    "print('R-squared:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepath = '../data/npmrd/brukerHembs.csv'\n",
    "x_testdata = genfromtxt(test_filepath,delimiter=',',encoding='utf-8-sig',skip_header=1)\n",
    "\n",
    "# Split data into X and y\n",
    "X_customtest = x_testdata[:,0:128]\n",
    "print(X_customtest)\n",
    "#128 --> pka & nmr\n",
    "#138 onwards --> electron density \n",
    "#y_customtest = x_testdata[:,135]\n",
    "\n",
    "predictions = lr.predict(X_customtest)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLEARN MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 136)\n",
      "[2.4  2.5  2.03 4.17 4.43 4.43 4.43 8.83 8.08 8.83 9.12 6.51 6.51 0.89\n",
      " 0.89 0.89 1.67 1.37 3.99 3.18 3.18 1.56 1.56 1.86 1.86 3.75 3.02 3.02\n",
      " 1.72 1.72 1.46 1.46 1.9  1.9  3.75 3.99 3.28 3.12 7.33 7.43 7.38 7.43\n",
      " 7.33 8.23 8.19 0.86 0.86 0.86 1.28 1.28 1.28 1.28 1.54 1.54 2.16 2.16\n",
      " 2.73 2.73 2.73 3.6  3.6  3.93 3.18 3.03 7.18 6.89 6.89 7.18 3.23 3.23\n",
      " 2.92 2.92 7.21 6.9  6.9  7.21 0.85 0.85 0.85 1.27 1.27 1.27 1.27 1.27\n",
      " 1.27 1.27 1.27 1.53 1.53 2.16 2.16 3.03 3.03 3.03 4.05 4.05 8.18 8.2\n",
      " 3.42 3.42 7.16 6.86 6.86 7.16 2.4  2.4  2.4  2.4  7.03 7.03 3.69 3.69\n",
      " 3.69 7.69 3.16 3.07 3.96 7.01 0.98 0.98 0.98 2.26 1.03 1.03 1.03 3.6\n",
      " 2.44 2.44 2.13 2.13 3.77 0.93 0.93 0.93 1.46 1.26 1.96 1.   1.   1.\n",
      " 3.66 3.53 3.53 7.37 7.3  7.3  7.3  7.37 7.67 4.64 4.64 7.44 7.42 7.38\n",
      " 7.42 7.44 4.12 2.34 2.06 2.   2.   3.41 3.33 8.24 8.34 6.06 4.29 3.91\n",
      " 3.83 4.43 4.81 3.75 3.75 3.75 8.16 7.17 3.24 3.31 3.96 3.93 3.78 3.7\n",
      " 4.58 3.49 3.64 3.85 7.59 8.7  8.24 8.92 1.24 1.24 1.24 4.13 4.13 2.07\n",
      " 2.07 2.07 2.36 2.36 2.36 3.54 3.54 3.17 3.17 2.55 2.55 3.   3.   1.89\n",
      " 1.89 2.29 2.29 1.15 1.15 1.15 2.54 1.15 1.15 1.15 6.43 4.39 3.7  3.98\n",
      " 2.75 2.18 4.08 3.81 3.71 3.75 2.04 2.12 2.35 2.35 3.03 3.03 3.03 3.92\n",
      " 3.92 7.8  6.91 6.91 7.8  3.98 3.24 3.15 7.09 7.88 0.86 0.86 0.86 1.28\n",
      " 1.28 1.28 1.28 1.6  1.6  2.36 2.36 4.15 4.15 1.24 1.24 1.24 4.05 3.47\n",
      " 3.29 7.31 7.53 7.19 7.27 7.72 1.32 1.32 1.32 4.24 3.58 1.27 1.27 1.27\n",
      " 4.22 4.22 4.39 1.4  1.4  1.4  6.05 7.83 5.9  4.12 3.92 3.81 4.2  4.3\n",
      " 0.93 0.93 0.93 2.09 0.93 0.93 0.93 2.6  2.6  7.95 6.27 2.75 2.48 4.6\n",
      " 4.1  3.79 3.73 2.71 2.71 2.71 2.71 2.71 2.71]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "\n",
    "# Load data into a Pandas DataFrame\n",
    "x_data = genfromtxt('../data/npmrd/embsnmr.csv',delimiter=',',encoding='utf-8-sig',skip_header=1)\n",
    "#x_data2 = genfromtxt('../data/embs/modelbreak/10-2-128-50-6-50/Oembslayer5-110000-120000-10dp.csv',delimiter=',',encoding='utf-8-sig',skip_header=1)\n",
    "\n",
    "print(x_data.shape)\n",
    "\n",
    "# Split data into X and y\n",
    "X = x_data[:,0:128]\n",
    "#128 --> pka & nmr\n",
    "#138 onwards --> electron density \n",
    "y = x_data[:,135]\n",
    "print(y)\n",
    "#label to split as well\n",
    "# Assuming your dataset is stored in X and y\n",
    "# X should contain the first 128 features, and y should contain the corresponding target values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "use_train_for_test = True \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aelsamma\\.conda\\envs\\dlchem2\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square-root Error: 0.029082190006987866\n",
      "0.9998384303578336\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Create an MLPRegressor model\n",
    "model = MLPRegressor(hidden_layer_sizes=(200,200,200,200), activation='relu', random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "if use_train_for_test == True:\n",
    "    # Make predictions\n",
    "    predictions_scaled = model.predict(X_train_scaled)\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1,1))\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    r2 = r2_score(y_train, predictions)\n",
    "else:\n",
    "    # Make predictions\n",
    "    predictions_scaled = model.predict(X_test_scaled)\n",
    "    predictions = scaler_y.inverse_transform(predictions_scaled.reshape(-1,1))\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "import math\n",
    "print(\"Mean Square-root Error:\", math.sqrt(mse))\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.32197978 3.36588588 3.28949483 5.62009138 6.03731386 3.4789245\n",
      "  3.58951822 6.70309147 5.69509121 4.96610521 3.97774356 3.26949187\n",
      "  3.96308612 3.53600166 4.46452566 3.67525827 3.68844514 4.090298\n",
      "  3.16882105 3.22273655 3.38802078 2.94731577 2.97288403 3.62546002]]\n"
     ]
    }
   ],
   "source": [
    "test_filepath = '../data/npmrd/brukerHembs.csv'\n",
    "x_testdata = genfromtxt(test_filepath,delimiter=',',encoding='utf-8-sig',skip_header=1)\n",
    "\n",
    "# Split data into X and y\n",
    "X_customtest = x_testdata[:,0:128]\n",
    "#128 --> pka & nmr\n",
    "#138 onwards --> electron density \n",
    "#y_customtest = x_testdata[:,128]\n",
    "\n",
    "predictions_scaled = model.predict(X_customtest)\n",
    "predictions = scaler_y.inverse_transform(predictions_scaled.reshape(1,-1))\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlchem2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
