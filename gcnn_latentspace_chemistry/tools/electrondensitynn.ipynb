{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amerelsamman/anaconda3/envs/dlchem/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#importing the libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class embeddings(Dataset):\n",
    "  def __init__(self,x_data,y_data):\n",
    "    self.x_data = torch.tensor(x_data,dtype=torch.float32)\n",
    "    self.y_data = torch.tensor(y_data,dtype=torch.float32)\n",
    "    self.length = self.x_data.shape[0]\n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_data[idx],self.y_data[idx]\n",
    "  def __len__(self):\n",
    "    return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the network\n",
    "from torch import nn\n",
    "class net(nn.Module):\n",
    "  def __init__(self,input_size,output_size):\n",
    "    super(net,self).__init__()\n",
    "    print(output_size)\n",
    "    self.l1 = nn.Linear(input_size,70)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.l2 = nn.Linear(70,output_size)\n",
    "  def forward(self,x_data):\n",
    "    output = self.l1(x_data)\n",
    "    output = self.relu(output)\n",
    "    output = self.l2(output)\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor(1.0549, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4109, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1111, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0578, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0499, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0401, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0340, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0317, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0298, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0282, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0267, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0254, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0243, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0224, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0216, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0208, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0189, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0183, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0178, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0173, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0169, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0165, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0161, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0157, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Load data into a Pandas DataFrame\n",
    "XY = genfromtxt('../data/embs/embsdensity-ince/embs250-5000woccspca.csv',delimiter=',',encoding='utf-8-sig',skip_header=1)\n",
    "# Split data into X and y\n",
    "x_data = XY[:,0:128]\n",
    "y_data = XY[:,138:141]\n",
    "label = XY[:,133:136]\n",
    "\n",
    "model = net(x_data.shape[1],y_data.shape[1])\n",
    "criterion = nn.MSELoss() #type of loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001) #learning rate\n",
    "epochs = 1500 #complexity of models\n",
    "\n",
    "dataset = embeddings(x_data,y_data)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset,shuffle=True,batch_size=100)\n",
    "\n",
    "costval = []\n",
    "X_train, X_test, y_train, y_test, label_train, label_test = train_test_split(x_data, y_data, label, test_size=0.25, random_state= 50)\n",
    "\n",
    "# Standardize the data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = torch.tensor(scaler_X.fit_transform(X_train),dtype=torch.float32)\n",
    "X_test_scaled = torch.tensor(scaler_X.transform(X_test),dtype=torch.float32)\n",
    "\n",
    "y_train_scaled = torch.tensor(scaler_y.fit_transform(y_train),dtype=torch.float32)\n",
    "y_test_scaled = torch.tensor(scaler_y.transform(y_test),dtype=torch.float32)\n",
    "\n",
    "for j in range(epochs):\n",
    "  for i,(x_train,y_train) in enumerate(dataloader):\n",
    "    #prediction\n",
    "    y_pred_scaled = model(X_train_scaled)\n",
    "    #calculating loss\n",
    "    cost = criterion(y_pred_scaled,y_train_scaled)\n",
    "    #backprop\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "  if j%50 == 0:\n",
    "    print(cost)\n",
    "    costval.append(cost)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.9956e-06, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#prediction\n",
    "y_pred_scaled = model(X_test_scaled)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled.detach().numpy())\n",
    "\n",
    "#print(y_test)\n",
    "#y_test = torch.tensor(y_test,dtype=torch.float32)\n",
    "#calculating loss\n",
    "cost = criterion(torch.tensor(y_pred),torch.tensor(y_test))\n",
    "\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1415, 3)\n",
      "(1415, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.shape(label_test))\n",
    "print(np.shape(y_pred))\n",
    "use_train_for_test = False\n",
    "\n",
    "for i in range(np.shape(y_pred)[1]):\n",
    "\n",
    "    if use_train_for_test == True: \n",
    "        save_predictions = np.column_stack((y_pred[:,i],y_train[:,i],label_train))\n",
    "    elif use_train_for_test == False: \n",
    "        save_predictions = np.column_stack((y_pred[:,i],y_test[:,i],label_test))\n",
    "        \n",
    "    save_pred_filepath = '../data/embs/embsdensity-ince/nntestpredictions%s.csv'  %(str(i)) \n",
    "    np.savetxt(save_pred_filepath,save_predictions,delimiter=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
